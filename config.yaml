# Llama Stack Configuration
llama_stack:
  url: "http://llama-stack:8000"  # Internal Docker network URL
  timeout: 120  # Request timeout in seconds

# Embedding Configuration
embedding:
  provider: "sentence-transformers-local"
  model: "jinaai/jina-embeddings-v3"
  api_key: ${HUGGINGFACE_API_KEY}  # Optional for free tier
  dimension: 1024
  batch_size: 16
  device: "cpu" #change to cuda if nvidia

# Chat/Completion Configuration 
chat:
  provider: "ollama"  
  model: "mistral:7b-instruct-v0.3"
  max_tokens: 2048
  temperature: 0.7
  context_length: 8192

# Database Configuration (for later when you connect)
database:
  url: ${POSTGRES_URL}
  vector_dimension: 1024