# Llama Stack Configuration
llama_stack:
  url: "http://localhost:8000"  # Internal Docker network URL
  timeout: 120  # Request timeout in seconds

# Embedding Configuration
embedding:
  provider: "ollama"
  model: "jina/jina-embeddings-v3"
  dimension: 1024  
  batch_size: 16

# Chat/Completion Configuration 
chat:
  provider: "ollama"  
  model: "mistral:7b-instruct-v0.3"
  max_tokens: 2048
  temperature: 0.7
  

# Database Configuration (for later when you connect)
database:
  url: ${VECTOR_DB_URL}
  vector_dimension: 1024