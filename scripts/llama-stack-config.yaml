version: "2"

# Image configuration
image:
  type: ollama

# Provider configurations
providers:
  # Inference provider - uses Ollama for chat/completion
  inference:
    - provider_id: ollama-inference
      provider_type: remote::ollama
      config:
        url: http://ollama:11434

  # Embedding provider - uses Ollama for embeddings
  embeddings:
    - provider_id: ollama-embeddings
      provider_type: remote::ollama
      config:
        url: http://ollama:11434

# Model definitions
# MODEL CHANGE: Update model names and dimensions here
models:
  # Chat/Completion model
  - model_id: mistral-chat
    provider_id: ollama-inference
    provider_model_id: mistral:latest
    metadata:
      model_type: llm
      # MODEL CHANGE:
      context_window: 8192

  # Embedding model  
  - model_id: nomic-embeddings
    provider_id: ollama-embeddings
    provider_model_id: nomic-embed-text:latest
    metadata:
      model_type: embedding
      # MODEL CHANGE:
      embedding_dimension: 768

# Shields configuration (optional safety layer)
shields: []

# Memory banks (for future RAG use)
memory_banks: []

# Telemetry
telemetry:
  enabled: false